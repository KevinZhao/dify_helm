# Default values for dify.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

# volume and volumeMounts would be injected to api and worker
volumes: []

volumeMounts: []

nameOverride: ""
fullnameOverride: ""

global:
  host: ""
  # Change this if your ingress is exposed with port other than 443, 80, like 8080 for instance
  port: ""
  enableTLS: true
  image:
    # Change this for new Dify version
    tag: "0.7.0"
  edition: "SELF_HOSTED"
  storageType: "s3"

  #---------------------------------------------------------------------#

  # enviroment variable injestion, please refer to Dify official document
  # https://docs.dify.ai/getting-started/install-self-hosted/environments

  # the following extra configs would be injected into:
  # * frontend
  # * api
  # * worker
  extraEnvs: []

  #---------------------------------------------------------------------#
  # the following extra configs would be injected into:
  # * api
  # * worker
  extraBackendEnvs:

  # SECRET_KEY is a must, A key used to securely sign session cookies and encrypt sensitive information in the database.This variable needs to be set when starting for the first time.
  # You can use "openssl rand -base64 42" to generate a strong key.

  # read more on the readme page for secret ref
  - name: SECRET_KEY
    value: ""
  # use "kubectl create secret generic dify --from-literal=SECRET_KEY=your_secret_value" to create s secret
  # use secretRef to protect your secret
  # - name: SECRET_KEY
  #   valueFrom:
  #     secretKeyRef:
  #       name: dify
  #       key: SECRET_KEY

  - name: LOG_LEVEL
    value: "DEBUG"

  #---------------------------------------------------------------------#
  # PostgreSQL database
  # RDS PostgreSQL or Aurora(PostgreSQL Compatatible) Database
  - name: DB_USERNAME
    value: "postgres"
  # it is adviced to use secret to manage you sensitive info including password
  - name: DB_PASSWORD
    value: ""
  - name: DB_HOST
    value: ""
  - name: DB_PORT
    value: "5432"
  - name: DB_DATABASE
    value: dify
  
  #---------------------------------------------------------------------#
  # Vector DB
  - name: VECTOR_STORE
    value: "opensearch"
    
  - name: OPENSEARCH_HOST
    value: ""
  - name: OPENSEARCH_PORT
    value: "443"
  - name: OPENSEARCH_USER
    value: "admin"
  - name: OPENSEARCH_PASSWORD
    value: ""
  - name: OPENSEARCH_SECURE
    value: "true"

  # Dify supports different kind of vector DB, please refer to below configuration
  # https://docs.dify.ai/v/zh-hans/getting-started/install-self-hosted/environments#xiang-liang-shu-ju-ku-pei-zhi

  #- name: VECTOR_STORE 
    #value: "qdrant"

  #- name: QDRANT_URL
  #  value: "http://your_host"

  #---------------------------------------------------------------------#
  # Redis
  # Elasticache Redis configuration
  - name: REDIS_HOST
    value: ""
  - name: REDIS_PORT
    value: "6379"
  - name: REDIS_DB
    value: "1"
  #- name: REDIS_USERNAME
  #  value: ""
  - name: REDIS_PASSWORD
    value: ""
  #- name: REDIS_USE_SSL
  #  value: "true"

  #---------------------------------------------------------------------#
  # Celery Configuration
  # Using below format
  # redis://<redis_username>:<redis_password>@<redis_host>:<redis_port>/<redis_database>
  # ex: redis://host:difyai123456@redis:6379/1
  
  - name: CELERY_BROKER_URL
    value: "redis://host:6379/0"

  #---------------------------------------------------------------------# 
  # S3
  - name: S3_ENDPOINT
    value: "https://your_bucket_name.s3.your_region.amazonaws.com"
  - name: S3_BUCKET_NAME
    value: "your_bucket_name"
  - name: S3_ACCESS_KEY
    value: ""
  - name: S3_SECRET_KEY
    value: ""
  - name: S3_REGION
    value: "your_region"

  # Provide extra labels for all deployments and related pods of this chart
  labels: {}

#***********************************************************************#
ingress:
  enabled: true
  className: "alb"
  annotations:
    kubernetes.io/ingress.class: "alb"
    alb.ingress.kubernetes.io/scheme: "internet-facing"  # 或 "internal"
    alb.ingress.kubernetes.io/target-type: "ip"
    #alb.ingress.kubernetes.io/listen-ports: '[{"HTTP": 80}]'
    alb.ingress.kubernetes.io/listen-ports: '[{"HTTPS": 443}]'
    alb.ingress.kubernetes.io/certificate-arn: "arn_of_your_certification"
  #tlsSecretName: "my-tls-secret" # 可以省略这行或留空
  hosts:
    - host: "dify.zhaokm.org"
      paths:
        - path: /api
          pathType: Prefix
          backend:
            serviceName: "dify-api-svc"
            servicePort: 80
        - path: /v1
          pathType: Prefix
          backend:
            serviceName: "dify-api-svc"
            servicePort: 80
        - path: /console/api
          pathType: Prefix
          backend:
            serviceName: "dify-api-svc"
            servicePort: 80
        - path: /files
          pathType: Prefix
          backend:
            serviceName: "dify-api-svc"
            servicePort: 80
        - path: /
          pathType: Prefix
          backend:
            serviceName: "dify-frontend"
            servicePort: 80

#***********************************************************************#
serviceAccount:
  # Specifies whether a service account should be created
  create: true
  # Annotations to add to the service account
  annotations: {}
  # The name of the service account to use.
  # If not set and create is true, a name is generated using the fullname template
  name: ""

#***********************************************************************#
frontend:
  replicaCount: 1

  image:
    repository: langgenius/dify-web
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""

  envs: []
  imagePullSecrets: []

  podAnnotations: {}

  podSecurityContext: {}
    # fsGroup: 2000

  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # OnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  service:
    annotations:
      service.beta.kubernetes.io/aws-load-balancer-healthcheck-path: "/apps"
      service.beta.kubernetes.io/aws-load-balancer-healthcheck-port: "80"
    type: ClusterIP
    port: 80

  containerPort: 3000

  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  nodeSelector: {}

  tolerations: []

  affinity: {}
  livenessProbe:
    httpGet:
      path: /apps
      port: http
      httpHeaders:
      - name: accept-language
        value: en
    initialDelaySeconds: 3
    timeoutSeconds: 5
    periodSeconds: 30
    successThreshold: 1
    failureThreshold: 2
  readinessProbe:
    httpGet:
      path: /apps
      port: http
      httpHeaders:
      - name: accept-language
        value: en
    initialDelaySeconds: 3
    timeoutSeconds: 5
    periodSeconds: 30
    successThreshold: 1
    failureThreshold: 2

#***********************************************************************#
api:
  replicaCount: 1

  image:
    repository: langgenius/dify-api
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""
  envs:
  # sandbox
  - name: CODE_MAX_NUMBER
    value: "9223372036854775807"
  - name: CODE_MIN_NUMBER
    value: "-9223372036854775808"
  - name: CODE_MAX_STRING_LENGTH
    value: "80000"
  - name: TEMPLATE_TRANSFORM_MAX_LENGTH
    value: "80000"
  - name: CODE_MAX_STRING_ARRAY_LENGTH
    value: "30"
  - name: CODE_MAX_OBJECT_ARRAY_LENGTH
    value: "30"
  - name: CODE_MAX_NUMBER_ARRAY_LENGTH
    value: "1000"
  imagePullSecrets: []

  podAnnotations: {}

  podSecurityContext: {}
    # fsGroup: 2000

  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  service:
    annotations:
      service.beta.kubernetes.io/aws-load-balancer-healthcheck-path: "/health"
      service.beta.kubernetes.io/aws-load-balancer-healthcheck-port: "80"
    type: ClusterIP
    port: 80

  containerPort: 5001

  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  nodeSelector: {}

  tolerations: []

  affinity: {}

  livenessProbe:
    httpGet:
      path: /health
      port: http
    initialDelaySeconds: 30
    timeoutSeconds: 5
    periodSeconds: 30
    successThreshold: 1
    failureThreshold: 2
  readinessProbe:
    httpGet:
      path: /health
      port: http
    initialDelaySeconds: 10
    timeoutSeconds: 5
    periodSeconds: 5
    successThreshold: 1
    failureThreshold: 10

#***********************************************************************#
worker:
  replicaCount: 1

  image:
    repository: langgenius/dify-api
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""

  imagePullSecrets: []

  podAnnotations: {}

  podSecurityContext: {}
    # fsGroup: 2000

  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000


  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  nodeSelector: {}

  tolerations: []

  affinity: {}

  # livenessprobe for worker, default no probe
  livenessProbe: {}
  readinessProbe: {}

#***********************************************************************#
sandbox:
  replicaCount: 1
  # please change to avoid abuse
  apiKey: "dify-sandbox"
  # prefer to use secret
  apiKeySecret: ""
  image:
    repository: langgenius/dify-sandbox
    pullPolicy: IfNotPresent
    # Overrides the image tag whose default is the chart appVersion.
    tag: ""
  config:
    # python_requirements: |
    #   numpy==1.20.3
    #   scipy==1.6.3
    python_requirements: ""

  envs:
  - name: GIN_MODE
    value: "release"
  - name: WORKER_TIMEOUT
    value: "15"
  imagePullSecrets: []

  podAnnotations: {}

  podSecurityContext: {}
    # fsGroup: 2000

  securityContext: {}
    # capabilities:
    #   drop:
    #   - ALL
    # readOnlyRootFilesystem: true
    # runAsNonRoot: true
    # runAsUser: 1000

  service:
    type: ClusterIP
    port: 80

  containerPort: 8194

  resources: {}
    # We usually recommend not to specify default resources and to leave this as a conscious
    # choice for the user. This also increases chances charts run on environments with little
    # resources, such as Minikube. If you do want to specify resources, uncomment the following
    # lines, adjust them as necessary, and remove the curly braces after 'resources:'.
    # limits:
    #   cpu: 100m
    #   memory: 128Mi
    # requests:
    #   cpu: 100m
    #   memory: 128Mi

  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 100
    targetCPUUtilizationPercentage: 80
    # targetMemoryUtilizationPercentage: 80

  nodeSelector: {}

  tolerations: []

  affinity: {}

  readinessProbe:
    tcpSocket:
      port: http
    initialDelaySeconds: 1
    timeoutSeconds: 5
    periodSeconds: 5
    successThreshold: 1
    failureThreshold: 10
  livenessProbe:
    tcpSocket:
      port: http
    initialDelaySeconds: 30
    timeoutSeconds: 5
    periodSeconds: 30
    successThreshold: 1
    failureThreshold: 2

#*******************dependencies****************************************#
# Production enviroment, please use managed services for data persistance
# Set embedded variable to True to use docker-compose
redis:
  # using embedded redis
  # connection info would be set automatically
  # best to use external redis if you have one
  #embedded: true
  # url: "redis://127.0.0.1:6379/0"
  # urlSecret: ""
  # urlSecretKey: "CACHE_URL"
  # please consult to chart manual if you want to change it.
  # https://artifacthub.io/packages/helm/bitnami/redis
  #architecture: standalone
  #auth:
  #  password: "REDIS_PASSWORD"
  #master:
  #  persistence:
  #    enabled: false
  #    size: 8Gi

  embedded: false

#*******************dependencies****************************************#
# Production enviroment, please use managed services for data persistance
# Set embedded variable to True to use docker-compose
postgresql:
  # using embedded postgresql
  # connection info would be set automatically
  # best to use external pg if you have one
  # setting embedded to false and set pg url in envrionment variable
  # embedded: true
  
  # goto extraBackendEnvs to set pg url
  # architecture: standalone
  # auth:
  #  postgresPassword: ""
  #  database: "dify"
  # primary:
  #  persistence:
  #    enabled: false

  embedded: false

#*******************dependencies****************************************#
# Production enviroment, please use managed services for data persistance
# Set embedded variable to True to use docker-compose
minio:
  #embedded: true
  # using embedded minio
  # connection info would be set automatically
  # best to use external s3/minio if you have one
  # setting embedded to false and set minio/s3 url in envrionment variable
  #auth:
  #  rootUser: minioadmin
  #  rootPassword: minioadmin
  #defaultBuckets: "dify"
  #persistence:
  #  enabled: false

  embedded: false